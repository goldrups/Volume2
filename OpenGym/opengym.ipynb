{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ1tKnrK4TcN"
   },
   "source": [
    "\n",
    "## Volume 2: OpenGym\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qbA8CjB3_IL"
   },
   "source": [
    "<Sam Goldrup\\>\n",
    "<Math 323\\>\n",
    "<3 March 2022\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUZ1Wq-8NwSn"
   },
   "source": [
    "**Note:** Some IPython notebook platforms (such as Google Colab) do not currently support rendering OpenAI environments. In order to properly render the OpenGym environments in this lab, you may need to run the Jupyter Notebook locally (for example, run it in VSCode or from the command line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqeTGS1PNvZ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZlMKi7Fx35TI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-rNQLwd429z"
   },
   "source": [
    "**Problem 1**\n",
    "\n",
    "*   Implement `random_blackjack()`.\n",
    "*   Run the game 500 times and output the percentage of games that are wins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lrhUolvq45vh"
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "def random_blackjack(n):\n",
    "    \"\"\"\n",
    "    Play a random game of Blackjack. Determine the\n",
    "    percentage the player wins out of n times.\n",
    "    Parameters:\n",
    "        n (int): number of iterations\n",
    "    Returns:\n",
    "        percent (float): percentage that the player\n",
    "                         wins\n",
    "    \"\"\"\n",
    "    env = gym.make(\"Blackjack-v1\")\n",
    "    dubs = 0\n",
    "    for i in range(n): \n",
    "        observation = env.reset() #gotta reset the environment\n",
    "        _,won,play_on,_ = env.step(env.action_space.sample()) #take a random step\n",
    "        while play_on == False: #while not done\n",
    "            _,won,play_on,_ = env.step(env.action_space.sample())\n",
    "        if won == 1:\n",
    "            dubs += 1\n",
    "            \n",
    "    env.close()\n",
    "    return 100*(dubs/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JF-bS3gyIx4k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.310000000000002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blackjack(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfZPCIMC5JmB"
   },
   "source": [
    "**Problem 2**\n",
    "\n",
    "* Implement `blackjack()`.\n",
    "* For `n` = 1, 2, ..., 21, plot the win percentage after 10,000 games of Blackjack.\n",
    "* Identify which value of `n` gives the highest win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6Uv7AD8I5LWk"
   },
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "def blackjack(n=11):\n",
    "    \"\"\"\n",
    "    Play blackjack with naive algorithm.\n",
    "    Parameters:\n",
    "        n (int): maximum accepted player hand\n",
    "    Return:\n",
    "        percent (float): percentage of 10000 iterations\n",
    "                         that the player wins\n",
    "    \"\"\"\n",
    "    dubs = 0\n",
    "    env = gym.make(\"Blackjack-v1\")\n",
    "\n",
    "    for i in range(10000):\n",
    "        observation = env.reset()\n",
    "        done = False #we will play while not \"done\"\n",
    "        \n",
    "        if observation[0] <= n:\n",
    "            draw = 1\n",
    "        else:\n",
    "            draw = 0\n",
    "        \n",
    "        while not done: #iterate until the game is over\n",
    "            hand,won,done,dontcare2 = env.step(draw)\n",
    "            if hand[0] <= n: #number of cards in the hand\n",
    "                draw = 1\n",
    "            else:\n",
    "                draw = 0\n",
    "        if won == 1:\n",
    "            dubs += 1\n",
    "                \n",
    "    env.close() #gotta make sure to close that environment\n",
    "            \n",
    "    return dubs/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "miBtqMaVIjFJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot here\n",
    "\n",
    "success_vals = []\n",
    "\n",
    "for j in range(21):\n",
    "    success_vals.append(blackjack(j)) #iterate over different max hand values\n",
    "    \n",
    "plt.plot(list(range(len(success_vals))),success_vals) #make the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY8vR6Ygxxk-"
   },
   "source": [
    "*Identify which value(s) give the highest winrate here*\n",
    "n=16 gives the best win rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9xB1KaZ5OJ3"
   },
   "source": [
    "**Problem 3**\n",
    "\n",
    "* Implement `cartpole()`.\n",
    "* Render the game and run your function once.\n",
    "* Run Cartpole 100 times (without rendering) and print out the average number of steps before it terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AGEUkBOx5Qbk"
   },
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "def cartpole(render=False):\n",
    "    \"\"\"\n",
    "    Solve CartPole-v0 by checking the velocity\n",
    "    of the tip of the pole.\n",
    "    Parameters: \n",
    "        render (bool): If True, render environment at each step\n",
    "    Return:\n",
    "        iterations (integer): number of steps or iterations\n",
    "                              to solve the environment\n",
    "    \"\"\"\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env.reset()\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    state = env.step(env.action_space.sample()) #position, angle, velocity, pole velocity\n",
    "    pos,ang,vel,p_vel,done= state[0][0],state[0][1],state[0][2],state[0][3],state[2] #get values for initial state\n",
    "    \n",
    "    while not done:\n",
    "        if render == True: #render the environment as an animation\n",
    "            env.render()\n",
    "        if p_vel > 0: # positive velocity means exert force the other way\n",
    "            state = env.step(1)\n",
    "            pos,ang,vel,p_vel,done = state[0][0],state[0][1],state[0][2],state[0][3],state[2]\n",
    "        else: #similar idea as above\n",
    "            state = env.step(0)\n",
    "            pos,ang,vel,p_vel,done = state[0][0],state[0][1],state[0][2],state[0][3],state[2]\n",
    "        steps += 1\n",
    "            \n",
    "    env.close() #shut it\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "78iSdRs6wZKb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Render the game and run once here\n",
    "cartpole(render=True) #to render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EaNbYfsuIhxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg with n=100:  196.3\n"
     ]
    }
   ],
   "source": [
    "# Run the game here and print average steps to termination\n",
    "step_tot = 0\n",
    "for i in range(100): #calculate an expectation\n",
    "    step_tot += cartpole()\n",
    "    \n",
    "print(\"avg with n=100: \", step_tot/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPFFk0nX5U_b"
   },
   "source": [
    "**Problem 4**\n",
    "\n",
    "* Implement `car()`.\n",
    "* Render the game and run your function once.\n",
    "* Run MountainCar 100 times (without rendering) and print out the average number of steps before it terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Lqq3Q6EO5Wgq"
   },
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "def car(render=False):\n",
    "    \"\"\"\n",
    "    Solve MountainCar-v0 by checking the position\n",
    "    of the car.\n",
    "    Parameters: \n",
    "        render (bool): If True, render environment at each step\n",
    "    Return:\n",
    "        iterations (integer): number of steps or iterations\n",
    "                              to solve the environment\n",
    "    \"\"\"\n",
    "    env = gym.make(\"MountainCar-v0\") #make the mountain car environment\n",
    "    env.reset()\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    state = env.step(env.action_space.sample())\n",
    "    pos,vel,done= state[0][0],state[0][1],state[2] #get initial position, velocity, and whether environment is don\n",
    "    steps = 1\n",
    "    \n",
    "    while not done:\n",
    "        if render == True: \n",
    "            env.render()\n",
    "        if pos < 0 and vel > 0:\n",
    "            state = env.step(2)\n",
    "            pos,vel,done= state[0][0],state[0][1],state[2]\n",
    "        elif pos > 0 and vel < 0:\n",
    "            state = env.step(0)\n",
    "            pos,vel,done= state[0][0],state[0][1],state[2]\n",
    "        elif pos > 0 and vel > 0:\n",
    "            state = env.step(2)\n",
    "            pos,vel,done= state[0][0],state[0][1],state[2]\n",
    "        else:\n",
    "            state = env.step(0)\n",
    "            pos,vel,done= state[0][0],state[0][1],state[2]\n",
    "        \n",
    "        steps += 1 #step count!\n",
    "        \n",
    "    env.close() #shut it\n",
    "    \n",
    "    \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4_kSEBYdwgnc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Render the game here\n",
    "car(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fUsBDn6KIgw5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.03\n"
     ]
    }
   ],
   "source": [
    "# Run the game here and print average steps to termination\n",
    "sum = 0\n",
    "for i in range(100):\n",
    "    sum += car()\n",
    "print(sum/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5tSd-zE4sHZ"
   },
   "source": [
    "**Helper Function for Problem 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zNNc3x9x09Zr"
   },
   "outputs": [],
   "source": [
    "def find_qvalues(env,alpha=.1,gamma=.6,epsilon=.1):\n",
    "    \"\"\"\n",
    "    Use the Q-learning algorithm to find qvalues.\n",
    "    Parameters:\n",
    "        env (str): environment name\n",
    "        alpha (float): learning rate\n",
    "        gamma (float): discount factor\n",
    "        epsilon (float): maximum value\n",
    "    Returns:\n",
    "        q_table (ndarray nxm)\n",
    "    \"\"\"\n",
    "    # Make environment\n",
    "    env = gym.make(env)\n",
    "    # Make Q-table\n",
    "    q_table = np.zeros((env.observation_space.n,env.action_space.n))\n",
    "\n",
    "    # Train\n",
    "    for i in range(1,100001):\n",
    "        # Reset state\n",
    "        state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0,0,0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Accept based on alpha\n",
    "            if random.uniform(0,1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            # Take action\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Calculate new qvalue\n",
    "            old_value = q_table[state,action]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            new_value = (1-alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state, action] = new_value\n",
    "\n",
    "            # Check if penalty is made\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            # Get next observation\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        # Print episode number\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Episode: {i}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    return q_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZODhO4AS5YQq"
   },
   "source": [
    "**Problem 5**\n",
    "\n",
    "* Render the \"`Taxi-v3`\" environment, act randomly until it terminates, and calculate the total reward\n",
    "* Render the \"`Taxi-v3`\" environment, use the Q-table to act optimally until it terminates, and calculate the total reward\n",
    "* Implement `taxi()`, then use it to print the average total reward for each algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e3i-LEnYKHyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| :\u001b[43m \u001b[0m|B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random actions Taxi game\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ejXeML7KJSJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Q-table actions Taxi game\n",
    "q_anon = find_qvalues(\"Taxi-v3\") #make the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_acts_of_kindness(render=False):\n",
    "    env = gym.make(\"Taxi-v3\")\n",
    "    rewards = 0 \n",
    "    env.reset() #gotta reset that environment\n",
    "    dontcare1, reward, done, dontcare2 = env.step(env.action_space.sample()) #make a random step\n",
    "    rewards += reward\n",
    "    done = False\n",
    "    while not done: #play while environment not done yet\n",
    "        if render==True:\n",
    "            env.render()\n",
    "        dontcare, reward, done, dontcare2 = env.step(env.action_space.sample()) #keep making random steps\n",
    "        rewards += reward\n",
    "    return rewards    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_version(q_table, render=False):\n",
    "    env = gym.make(\"Taxi-v3\")\n",
    "    total_qreward = 0\n",
    "    \n",
    "    env.reset()\n",
    "    pos = env.reset() #get initial position\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        if render == True:\n",
    "            env.render()\n",
    "        pos, score, done, dntcare = env.step(np.argmax(q_table[pos])) #greedily optimal position on the q table\n",
    "        total_qreward += score #add up successively\n",
    "        \n",
    "    env.close()\n",
    "    \n",
    "    return total_qreward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "APK2iYQV5aR4"
   },
   "outputs": [],
   "source": [
    "def taxi(q_table):\n",
    "    \"\"\"\n",
    "    Compare naive and q-learning algorithms.\n",
    "    Parameters:\n",
    "        q_table (ndarray nxm): table of qvalues\n",
    "    Returns:\n",
    "        naive (float): mean reward of naive algorithm\n",
    "                       of 10000 runs\n",
    "        q_reward (float): mean reward of Q-learning algorithm\n",
    "                          of 10000 runs\n",
    "    \"\"\"\n",
    "    env = gym.make(\"Taxi-v3\")\n",
    "    naive_reward = 0\n",
    "    q_reward = 0\n",
    "    for i in range(10000):\n",
    "        naive_reward += random_acts_of_kindness() #add up to get average for method\n",
    "        q_reward += q_version(q_table) #add up to get average for method\n",
    "    return naive_reward/10000,q_reward/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PhS7JR1JKOQu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-769.8919, 7.9558)\n"
     ]
    }
   ],
   "source": [
    "# Print the average rewards of the Taxi game for both algorithms run 10,000 times\n",
    "print(taxi(q_anon))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "opengym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
